---
title: "Causal inference is not a statistical problem"
author: 
 - "Lucy D'Agostino McGowan"
 - "Travis Gerke"
 - "Malcolm Barrett"
format: 
  pdf:
    keep-tex: true
    linestretch: 2
execute: 
  echo: false
  message: false
  warning: false
editor_options: 
  chunk_output_type: console
bibliography: citations.bib
---

```{r}
library(tidyverse)
library(patchwork)
options(
  ggplot2.discrete.colour = ggokabeito::palette_okabe_ito(),
  ggplot2.discrete.fill = ggokabeito::palette_okabe_ito(),
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

# set default theme
theme_set(
  theme_minimal(
    base_size = 14, 
    base_family = "sans"
  ) %+replace% 
    theme(
      panel.grid.minor = element_blank(),
      legend.position = "bottom"
    )
)
theme_dag <- function() {
  ggdag::theme_dag(base_family = "sans")
}
geom_dag_label_repel <- function(..., seed = 10) {
  ggdag::geom_dag_label_repel(
    aes(x, y, label = label),
    box.padding = 3.5, 
    inherit.aes = FALSE,
    max.overlaps = Inf, 
    family = "sans",
    seed = seed,
    label.size = NA, 
    label.padding = 0.1,
    size = 14 / 3,
    ...
  ) 
}

```

## Abstract

This paper introduces a collection of four data sets, similar to Anscombe's Quartet, that aim to highlight the challenges involved when estimating causal effects. Each of the four data sets is generated based on a distinct causal mechanism: the first consists of a collider, the second involves a confounder, the third involves a mediator, and the fourth involves the induction of M-Bias by an included factor. The paper contains a mathematical summary of each data set and directed acyclic graphs depicting the relationships between the variables. Even though the statistical summaries and visualizations for each data set are identical, the true causal effect differs. Correctly estimating the effect requires knowledge of the data-generating mechanism. These example data sets can help practitioners gain a better understanding of the assumptions underlying causal inference methods and emphasize the importance of gathering more information beyond what can be obtained from statistical tools alone. The paper also includes R code for reproducing all figures and provides access to the data sets through an R package named quartets. 

## Introduction

Anscombe's Quartet is a set of four data sets with the same summary statistics (means, variances, correlations, and linear regression fits) but exhibit different distributions and relationships when plotted on a graph [@anscombe1973graphs]. Often used to teach introductory statistics courses, Anscombe created the quartet to illustrate the importance of visualizing data before drawing conclusions based on statistical analyses alone. Here, we propose a different quartet, where statistical summaries do not provide insight into the underlying mechanism, but even visualizations do not solve the issue. In these examples, to correctly capture the relationship between the available factors, the research needs to understand or make assumptions about the data-generating mechanism. This proposed quartet can help practitioners better understand the assumptions underlying causal inference methods, further driving home the point that we require more information than can be gleaned from statistical tools alone to estimate causal effects accurately.

The data generated to create the figures displayed here are available in an R package titled `quartets` [@quartet].

## Causal inference primer

In causal inference, we often try to estimate the effect of some exposure, $X$, on some outcome $Y$. One framework to think through this problem is the "potential outcomes" framework [@rubin1974estimating]. Here, you can imagine each individual has a set of potential outcomes under each possible exposure value. For example, if there are two levels of exposure (exposed: 1 and unexposed: 0), we could have the potential outcome under exposure ($Y(1)$) and the potential outcome under no exposure ($Y(0)$) and look at the difference between these, $Y(1) - Y(0)$ to understand the impact on the exposure on the outcome, $Y$. Of course, at any moment, only one of these potential outcomes is observable: the potential outcome corresponding to the exposure the individual *actually* experienced. Under certain assumptions, we can borrow information from individuals who have received different exposures to compare the average difference between their observed outcomes. We assume that one individual's exposure does not impact the outcome of any other individual. We also assume that everyone has some chance of having each level of the exposure. And finally, we assume that the exposure the person receives has nothing to do with how we think it will affect them after adjusting for a set of observed covariates. In other words, the potential outcomes are independent of the exposure value the individual experienced given the covariate(s) *that we adjust for* in our modeling process. Of course, the entire point of causal inference is because we believe an exposure may cause an outcome; this assumption relates to the *assignment* to a specific exposure value. The easiest way to think about this is when the exposure is *randomly assigned* to each individual, ensuring this assumption is true without needing to adjust for any other factors. In non-randomized settings, we must likely adjust for other factors to satisfy this independence. The problem is identifying which factors are required, as adjusting for all observed factors may not be appropriate (and may even give you the wrong effect). The purpose of this paper is to focus on the observed covariates, $Z$. Given you have three variables, an exposure, $X$, an outcome, $Y$, and some measured factor, $Z$, how do you decide whether you should estimate the average treatment effect adjusting for $Z$?

## Methods

We propose the following four data generation mechanisms, summarized by the equations below and the directed acyclic graphs displayed in @fig-1. Here, $X$ is presumed to be some continuous exposure of interest, $Y$ a continuous outcome, and $Z$ a known, measured factor. The M-Bias equation includes two additional, unmeasured factors, $U_1$ and $U_2$.

(1) Collider:

$$
\begin{split}
X &\sim N(0, 1)\\
Y &= X + \varepsilon_y, \textrm{ }\varepsilon_y\sim N(0, 1)\\
Z &=  0.45X + 0.77 Y + \varepsilon_z, \textrm{ }\varepsilon_z \sim N(0,1)
\end{split}
$$ {#eq-col}

(2) Confounder:

$$
\begin{split}
Z &\sim N(0, 1)\\
X &= Z + \varepsilon_x,\textrm{ }\varepsilon_x\sim N(0, 1)\\
Y &=  0.5X + Z + \varepsilon_y, \textrm{ }\varepsilon_y\sim N(0, 1)
\end{split}
$$ {#eq-conf}

(3) Mediator:

$$
\begin{split}
X &\sim N(0, 1)\\
Z &= X + \varepsilon_z, \textrm{ }\varepsilon_z\sim N(0, 1)\\
Y &=  Z + \varepsilon_y, \textrm{ }\varepsilon_y\sim N(0, 1)
\end{split}
$$ {#eq-med}

(4) M-Bias:

$$
\begin{split}
U_1 &\sim N(0, 1)\\
U_2 &\sim N(0, 1)\\
Z &= 8 U_1 + U_2 + \varepsilon_z, \textrm{ }\varepsilon_z\sim N(0, 1)\\
X &=  U_1 + \varepsilon_x, \textrm{ }\varepsilon_x\sim N(0, 1)\\
Y &=  X + U_2 + \varepsilon_y, \textrm{ }\varepsilon_y\sim N(0, 1)
\end{split}
$$ {#eq-mbias}

In each of these scenarios, a linear model fit to estimate the relationship between $X$ and $Y$ with no further adjustment will result in a $\hat\beta$ coefficient of 1. Or, equivalently, the estimated average treatment effect (ATE) without adjusting for $Z$ is 1. The correlation between $X$ and the additional known factor $Z$ is also 0.70.

We have simulated 100 data points from each of the four mechanisms; we display each in @fig-2. This set of figures demonstrates that despite the very different data-generating mechanisms, there is no clear way to determine the "appropriate" way to model the effect of the exposure $X$ and the outcome $Y$ without additional information. For example, the unadjusted models are displayed in @fig-2, showing a relationship between $X$ and $Y$ of 1. The unadjusted models are the correct causal model for data-generating mechanisms (1) and (4); however, it overstates the effect of $X$ for data-generating mechanism (2) and describes the total effect of $X$ on $Y$ for data-generating mechanism (3), but not the direct effect (@tbl-1). Even examining the correlation between $X$ and the known factor $Z$ does not help us determine whether adjusting for $Z$ is appropriate, as it is 0.7 in all cases (@tbl-2). The four datasets are available in the `quartets` R package [@quartet].

```{r}
#| label: fig-1
#| fig-cap: "Directed Acyclic Graphs describing the four data generating mechanisms: (1) Collider (2) Confounder (3) Mediator (4) M-Bias."
#| fig-height: 6

library(ggdag)
library(ggokabeito)

expander <- function() {
  expand_plot(
    expand_x = expansion(c(0.01, 0.05)), 
    expand_y = expansion(c(0.2, 0.2))
  )
}

coords <- list(
  x = c(X = 2, Z = 1, Y = 3),
  y = c(X = 1, Z = 1.1, Y = 1)
)
d_conf <- dagify(
  X ~ Z,
  Y ~ X + Z,
  exposure = "X",
  outcome = "Y",
  labels = c(X = "X", Y = "Y", Z = "Z"),
  coords = coords
)

coords <- list(
  x = c(X = 1, Z = 3, Y = 2),
  y = c(X = 1, Z = 1.1, Y = 1)
)
d_coll <- dagify(
  Z ~ X + Y,
  Y ~ X,
  exposure = "X",
  outcome = "Y",
  labels = c(X = "X", Y = "Y", Z = "Z"),
  coords = coords
)

coords <- list(
  x = c(X = 1, Z = 2, Y = 3),
  y = c(X = 1, Z = 1.1, Y = 1)
)
d_med <- dagify(
  Z ~ X,
  Y ~ Z,
  exposure = "X",
  outcome = "Y",
  labels = c(X = "X", Y = "Y", Z = "Z"),
  coords = coords
)

coords <- list(
  x = c(U1 = 1, U2 = 2, X = 3, Z = 3, Y = 5),
  y = c(U1 = 2, U2 = 4, X = 1, Z = 2, Y = 2)
)
d_mbias <- dagify(
  Z ~ U1 + U2,
  X ~ U1,
  Y ~ X + U2,
  exposure = "X",
  outcome = "Y",
  labels = c(X = "X", Y = "Y", Z = "Z"),
  coords = coords
)

d_mbias |>
  tidy_dagitty() |>
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point(aes(color = label)) +
  geom_dag_edges() +
  geom_dag_text() +
  theme_dag() +
  coord_cartesian(clip = "off") +
  scale_color_manual(values = c("#A8CF9E", "#51c1ad", "#357edd")) +
  ggtitle("(4) M-bias") +
  theme(legend.position = "none") +
  expander() -> p_m_bias

d_coll |>
  tidy_dagitty() |>
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point(aes(color = label)) +
  geom_dag_edges() +
  geom_dag_text() +
  theme_dag() +
  coord_cartesian(clip = "off") +
  scale_color_manual(values = c("#A8CF9E", "#51c1ad", "#357edd")) +
  theme(legend.position = "none") +
  ggtitle("(1) Collider") +
  expander()  -> p_coll

d_med |>
  tidy_dagitty() |>
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point(aes(color = label)) +
  geom_dag_edges() +
  geom_dag_text() +
  theme_dag() +
  coord_cartesian(clip = "off") +
  scale_color_manual(values = c("#A8CF9E", "#51c1ad", "#357edd")) +
  theme(legend.position = "none") +
  ggtitle("(3) Mediator") +
  expander()  -> p_med

d_conf |>
  tidy_dagitty() |>
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point(aes(color = label)) +
  geom_dag_edges() +
  geom_dag_text() +
  theme_dag() +
  coord_cartesian(clip = "off") +
  scale_color_manual(values = c("#A8CF9E", "#51c1ad", "#357edd")) +
  theme(legend.position = "none") +
  ggtitle("(2) Confounder") + 
  expander() -> p_conf

(p_coll + plot_spacer() + p_conf) /  (p_med + plot_spacer() + p_m_bias)  
```

```{r}
#| fig-cap: "100 points generated using the data generating mechanisms specified (1) Collider (2) Confounder (3) Mediator (4) M-Bias. The blue line displays a linear regression fit estimating the relationship between X and Y; in each case, the slope is 1. "
#| label: fig-2
library(tidyverse)
# install.packages("quartets")
library(quartets)

## Figure 2

ggplot(causal_quartet, aes(x = exposure, y = outcome)) +
  geom_point(alpha = 0.25) + 
  geom_smooth(
    method = "lm", 
    formula = "y ~ x", 
    linewidth = 1.1, 
    color = "steelblue"
  ) +
  facet_wrap(~dataset)
```

+---------------------------+---------------------------+-----------------------+
| Data generating mechanism | Correct causal model      | Correct causal effect |
+===========================+===========================+=======================+
| \(1\) Collider            | Y \~ X                    | 1                     |
+---------------------------+---------------------------+-----------------------+
| \(2\) Confounder          | Y \~ X ; Z                | 0.5                   |
+---------------------------+---------------------------+-----------------------+
| \(3\) Mediator            | Direct effect: Y \~ X ; Z | Direct effect: 0      |
|                           |                           |                       |
|                           | Total Effect: Y \~ X      | Total effect: 1       |
+---------------------------+---------------------------+-----------------------+
| \(4\) M-Bias              | Y \~ X                    | 1                     |
+---------------------------+---------------------------+-----------------------+

: Correct causal models and causal effects for each data-generating mechanism. The notation $X ; Z$ implies that we should adjust for $Z$ when estimating the causal effect. In other words, for the confounder data-generating mechanism and direct effect mediator model, the potential outcomes are independent of exposure given the observed covariate $Z$. {#tbl-1}


```{r}
#| label: tbl-2
#| tbl-cap: "Coefficients for the exposure under each data generating mechanism depending on the model fit as well as the correlation between $X$ and $Z$."

## Table 2
round_coefs <- function(.mdl) {
  round(coef(.mdl)[2], 2)
}

causal_quartet |>
  nest_by(dataset) |>
  mutate(
    `ATE not adjusting for Z` = round_coefs(lm(outcome ~ exposure, data = data)),
    `ATE adjusting for Z` = round_coefs(lm(outcome ~ exposure + covariate, data = data)),
    `Correlation of X and Z` = round(cor(data$exposure, data$covariate), 2)
  ) |>
  select(-data, dataset) |>
  knitr::kable(
    "latex", 
    booktabs = TRUE,
    escape = FALSE, 
    col.names = kableExtra::linebreak(c(
      "Data generating mechanism", 
      "ATE\nnot adjusting for Z", 
      "ATE\nadjusting for Z", 
      "Correlation of\nX and Z"
      ), align = "c")
  ) 
```

## The Solution

Here we have demonstrated that when presented with an exposure, outcome, and some measured factors, statistics alone, whether summary statistics or data visualizations are insufficient to determine the appropriate causal estimate. Analysts need additional information about the data-generating mechanism to draw the correct conclusions. While knowledge of the data-generating process is necessary to estimate the right causal effect in each of the cases presented, an analyst can take steps to make mistakes such as those shown here less likely. The first is discussing understood mechanisms with content matter experts before estimating causal effects. Drawing the proposed relationships via causal diagrams such as the directed acyclic graphs shown in @fig-1 before calculating any statistical quantities can help the analyst ensure they are only adjusting for factors that meet the "backdoor criterion," that is, adjusting for only factors that close all backdoor paths between the exposure and outcome of interest [@pearl2000causality]. 

```{r}
#| label: fig-3
#| fig-cap: "Time-ordered collider DAG where each factor is measured twice. $X$ is the exposure, $Y$ is the outcome, and $Z$ is the measured factor. The highlighted $Z$ node indicates which time point is being adjusted for when estimating the average treatment effect of the highlighted $X$ on the highlighted $Y$"
#| fig-subcap: 
#|   - "Adjusting for $Z$ as shown here would induce collider bias."
#|   - "Adjusting for this pre-exposure $Z$ as shown here would **not** induce collider bias."
#| layout-ncol: 2
coords <- list(
  x = c(X_0 = 1, X_1 = 2, Z_1 = 2, Y_1 = 1.9, X_2 = 3, Y_2 = 2.9, Z_2 = 3,
        X_3 = 4, Y_3 = 3.9, Z_3 = 4),
  y = c(X_0 = 1, Y_0 = 1.05,
        X_1 = 1, Z_1 = 1.1, Y_1 = 1.05,
        X_2 = 1, Z_2 = 1.1, Y_2 = 1.05,
        X_3 = 1, Z_3 = 1.1, Y_3 = 1.05)
)
d_coll <- dagify(
  Y_2 ~ X_1,
  Y_3 ~ X_2,
  X_2 ~ X_1,
  Z_2 ~ X_1 + Y_2,
  Z_3 ~ X_2 + Y_3 + Z_2,
  exposure = "X_2",
  outcome = "Y_3",
  labels = c(X_0 = "X",
             X_1 = "X",
             X_2 = "X",
             X_3 = "X",
             Y_0 = "Y",
             Y_1 = "Y",
             Y_2 = "Y",
             Y_3 = "Y",
             Z_1 = "Z",
             Z_2 = "Z",
             Z_3 = "Z"),
  coords = coords
)

d_coll |>
  tidy_dagitty() |>
  mutate(color = case_when(
    !(name %in% c("X_2", "Y_3", "Z_3")) ~ "grey",
    TRUE ~ label)) |>
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point(aes(color = color)) +
  geom_dag_edges() +
  geom_dag_text(aes(label = label)) +
  theme_dag() +
  coord_cartesian(clip = "off")  +
  scale_color_manual(values = c("lightgrey", "#A8CF9E", "#51c1ad", "#357edd")) +
  theme(legend.position = "none") + 
  geom_vline(xintercept = c(2.6, 3.25, 3.6, 4.25), lty = 2) + 
  annotate("label", x = 2.925, y = 0.97, label = "baseline") + 
  annotate("label", x = 3.925, y = 0.97, label = "follow-up")

d_coll |>
  tidy_dagitty() |>
  mutate(color = case_when(
    !(name %in% c("X_2", "Y_3", "Z_2")) ~ "grey",
    TRUE ~ label)) |>
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point(aes(color = color)) +
  geom_dag_edges() +
  geom_dag_text(aes(label = label)) +
  theme_dag() +
  coord_cartesian(clip = "off")  +
  scale_color_manual(values = c("lightgrey", "#A8CF9E", "#51c1ad", "#357edd")) +
  theme(legend.position = "none") + 
  geom_vline(xintercept = c(2.6, 3.25, 3.6, 4.25), lty = 2) + 
  annotate("label", x = 2.925, y = 0.97, label = "baseline") + 
  annotate("label", x = 3.925, y = 0.97, label = "follow-up")
```

Absent subject matter expertise, the analyst can at least consider the time ordering of the available factors. Fundamental principles of causal inference dictate that the exposure of interest must precede the outcome of interest to establish a causal relationship plausibly. In addition, to account for potential confounding, any covariates adjusted for in the analysis must precede the exposure in time. Including this additional timing information would omit the potential for two of the three misspecified models above (@eq-col the "collider" and @eq-med the "mediator") as the former would demonstrate that the factor $Z$ falls after both the exposure and outcome and the latter would show that the factor $Z$ falls between the exposure and the outcome in time. For example, if we drew the second panel of @fig-1 (the Collider) as a time-ordered DAG, we would see something like @fig-3. If we carefully adjust only for factors that are measured pre-exposure, we would not induce the bias we see in @tbl-2 (@fig-3-2). The Causal Quartets data sets are accompanied by four data sets with time-varying measures for each factor, $X$, $Y$, and $Z$, generated under the same data-generating mechanisms. If we adjust for the pre-exposure measurement of $Z$, we get the correct causal effect in all scenarios except M-Bias (@tbl-3).

```{r}
#| label: tbl-3
#| tbl-cap: "Coefficients for the exposure under each data generating mechanism depending on the model fit as well as the correlation between $X$ and $Z$."

## Table 3

causal_quartet_time |>
  nest_by(dataset) |>
  mutate(
    `ATE not adjusting for Z` = 
      round_coefs(lm(outcome_followup ~ exposure_baseline, data = data)),
    `ATE adjusting for Z` = 
      round_coefs(lm(
        outcome_followup ~ exposure_baseline + covariate_baseline, 
        data = data
      ))
  ) |>
  bind_cols(tibble(truth = c(1, 0.5, 1, 1))) |>
  select(-data, dataset) |>
  knitr::kable(
    "latex", 
    booktabs = TRUE,
    escape = FALSE, 
    col.names = kableExtra::linebreak(c(
      "Data generating mechanism", 
      "ATE\nnot adjusting for\npre-exposure Z", 
      "ATE\nadjusting for\npre-exposure Z",
      "Correct causal effect"), align = "c"),
    digits = 2
  ) 
```

Adjusting for only pre-exposure factors is widely recommended. The only exception is when a known confounder is only measured after the exposure in a particular data analysis, in which case some experts recommend adjusting for it. Still, even then, caution is advised [@groenwold2021adjust]. Many causal inference methodologists would recommend conditioning on *all* measured pre-exposure factors [@rosenbaumconstructing; @rubin2009should; @rubin1996matching; @rubin2008objective]. Including timing information alone (and thus adjusting for all pre-exposure factors) does not preclude one from mistakenly fitting the adjusted model under the fourth data generating mechanism (M-bias), as $Z$ can fall temporally before $X$ and $Y$ and still induce bias. Some authors have argued, however, that this strict M-bias (e.g., where $U_1$ and $U_2$ in @eq-mbias have no relationship with each other and $Z$ has no relationship with $X$ or $Y$ other than via $U_1$ and $U_2$) is very rare in most practical settings [@liu2012implications; @rubin2009should; @gelman2011causality]. Indeed, even theoretical results have demonstrated that bias induced by this data-generating mechanism is sensitive to deviations from this form [@ding2015adjust].

## Discussion

Anscombe's Quartet has inspired the use of small data sets to demonstrate key concepts in various data analytic problems. Recent examples include an extension of the original idea proposed by Anscombe called the "Datasaurus Dozen" [@matejka2017same], an exploration of varying interaction effects [@rohrer2021precise], a quartet of model types fit to the same data that yield the same performance metrics but fit very different underlying mechanisms [@biecek2023performance], and a set of conceptual causal quartets that highlight the impact of treatment heterogeneity on the average treatment effect [@gelman2023causal]. While similar in name, the conceptual causal quartets differ from what we present here as they provide excellent insight into how variation in a treatment effect/treatment heterogeneity can impact an average treatment effect (by plotting the latent true causal effect). Both sets provide essential and complementary understanding for data analysis practitioners.

We have presented four example data sets demonstrating the importance of understanding the data-generating mechanism when attempting to answer causal questions. These data indicate that more than statistical summaries and visualizations are needed to provide insight into the underlying relationship between the variables. An understanding or assumption of the data-generating mechanism is required to capture causal relationships correctly. These examples underscore the limitations of relying solely on statistical tools in data analyses and highlight the crucial role of domain-specific knowledge. Moreover, they emphasize the importance of considering the timing of factors when deciding what to adjust for.

## References

::: {#refs}
:::

## Appendix {.appendix}

R code to generate the tables and figures:

```{r}
#| eval: false
#| echo: true
#| ref.label: ["fig-2", "tbl-2", "tbl-3"]
```


