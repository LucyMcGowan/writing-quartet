---
title: "Causal inference is not a statistical problem"
author: 
 - "Lucy D'Agostino McGowan"
 - "Malcolm Barrett"
format: pdf
execute: 
  echo: false
  message: false
  warning: false
editor_options: 
  chunk_output_type: console
bibliography: citations.bib
---

```{r}
library(tidyverse)
library(patchwork)
options(
  ggplot2.discrete.colour = ggokabeito::palette_okabe_ito(),
  ggplot2.discrete.fill = ggokabeito::palette_okabe_ito(),
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

# set default theme
theme_set(
  theme_minimal(
    base_size = 14, 
    base_family = "sans"
  ) %+replace% 
    theme(
      panel.grid.minor = element_blank(),
      legend.position = "bottom"
    )
)
theme_dag <- function() {
  ggdag::theme_dag(base_family = "sans")
}
geom_dag_label_repel <- function(..., seed = 10) {
  ggdag::geom_dag_label_repel(
    aes(x, y, label = label),
    box.padding = 3.5, 
    inherit.aes = FALSE,
    max.overlaps = Inf, 
    family = "sans",
    seed = seed,
    label.size = NA, 
    label.padding = 0.1,
    size = 14 / 3,
    ...
  ) 
}

```

## Introduction

Anscombe's quartet is a set of four data sets with the same summary statistics (means, variances, correlations, and linear regression fits) but exhibit different distributions and relationships when plotted on a graph [@anscombe1973graphs]. Often used to teach introductory statistics courses, Anscombe created the quartet to illustrate the importance of visualizing data before drawing conclusions based on statistical analyses alone. Here, we propose a different quartet, where statistical summaries do not provide insight into the underlying mechanism, but even visualizations do not solve the issue. In these examples, an understanding or assumption of the data-generating mechanism is required to capture the relationship between the available factors correctly. This proposed quartet can help practitioners better understand the assumptions underlying causal inference methods, further driving home the point that we require more information than can be gleaned from statistical tools alone to estimate causal effects accurately.

The data generated to create the figures displayed here are available in an R package titled `quartet` [@quartet].

## Methods

We propose the following four data generation mechanisms, summarized by the equations below, as well as the directed acyclic graphs displayed in @fig-1. Here, $X$ is presumed to be some continuous exposure of interest, $Y$ a continuous outcome, and $Z$ a known, measured factor. The M-Bias equation includes two additional, unmeasured factors, $U_1$ and $U_2$.

(1) Collider:

$$
\begin{split}
X &\sim N(0, 1)\\
Y &= X + \varepsilon_y, \textrm{ }\varepsilon_y\sim N(0, 1)\\
Z &=  0.45X + 0.77 Y + \varepsilon_z, \textrm{ }\varepsilon_z \sim N(0,1)
\end{split}
$$ {#eq-col}

(2) Confounder:

$$
\begin{split}
Z &\sim N(0, 1)\\
X &= Z + \varepsilon_x,\textrm{ }\varepsilon_x\sim N(0, 1)\\
Y &=  0.5Z + \varepsilon_y, \textrm{ }\varepsilon_y\sim N(0, 1)
\end{split}
$$ {#eq-conf}

(3) Mediator:

$$
\begin{split}
X &\sim N(0, 1)\\
Z &= X + \varepsilon_z, \textrm{ }\varepsilon_z\sim N(0, 1)\\
Y &=  Z + \varepsilon_y, \textrm{ }\varepsilon_y\sim N(0, 1)
\end{split}
$$ {#eq-med}

(4) M-Bias:

$$
\begin{split}
U_1 &\sim N(0, 1)\\
U_2 &\sim N(0, 1)\\
Z &= 8 U_1 + U_2 + \varepsilon_z, \textrm{ }\varepsilon_z\sim N(0, 1)\\
X &=  U_1 + \varepsilon_x, \textrm{ }\varepsilon_x\sim N(0, 1)\\
Y &=  X + U_2 + \varepsilon_y, \textrm{ }\varepsilon_y\sim N(0, 1)
\end{split}
$$ {#eq-mbias}

In each of these scenarios, a linear model fit to estimate the relationship between $X$ and $Y$ with no further adjustment will result in a $\hat\beta$ coefficient of 1. The correlation between $X$ and the additional known factor $Z$ is also 0.70.

We have simulated 100 data points from each of the four mechanisms; we display each in @fig-2. This set of figures demonstrates that despite the very different data-generating mechanisms, there is no clear way to determine the "appropriate" way to model the effect of the exposure $X$ and the outcome $Y$ without additional information. For example, the unadjusted models are displayed in @fig-2, showing a relationship between $X$ and $Y$ of 1. The unadjusted models are the correct causal model for data-generating mechanisms (1) and (4); however, it overstates the effect of $X$ for data-generating mechanism (2) and describes the total effect of $X$ on $Y$ for data-generating mechanism (3), but not the direct effect (@tbl-1). Even examining the correlation between $X$ and the known factor $Z$ does not help us determine whether adjusting for $Z$ is appropriate, as it is 0.7 in all cases (@tbl-2).

```{r}
#| label: fig-1
#| fig-cap: "Directed Acyclic Graphs describing the four data generating mechanisms: (1) Collider (2) Confounder (3) Mediator (4) M-Bias."
#| fig-height: 6

library(ggdag)
library(tidyverse)
library(ggokabeito)
library(patchwork)

expander <- function() {
  expand_plot(
    expand_x = expansion(c(0.01, 0.05)), 
    expand_y = expansion(c(0.2, 0.2))
  )
}

coords <- list(
  x = c(X = 2, Z = 1, Y = 3),
  y = c(X = 1, Z = 1.1, Y = 1)
)
d_conf <- dagify(
  X ~ Z,
  Y ~ X + Z,
  exposure = "X",
  outcome = "Y",
  labels = c(X = "X", Y = "Y", Z = "Z"),
  coords = coords
)

coords <- list(
  x = c(X = 1, Z = 3, Y = 2),
  y = c(X = 1, Z = 1.1, Y = 1)
)
d_coll <- dagify(
  Z ~ X + Y,
  Y ~ X,
  exposure = "X",
  outcome = "Y",
  labels = c(X = "X", Y = "Y", Z = "Z"),
  coords = coords
)

coords <- list(
  x = c(X = 1, Z = 2, Y = 3),
  y = c(X = 1, Z = 1.1, Y = 1)
)
d_med <- dagify(
  Z ~ X,
  Y ~ Z,
  exposure = "X",
  outcome = "Y",
  labels = c(X = "X", Y = "Y", Z = "Z"),
  coords = coords
)

coords <- list(
  x = c(U1 = 1, U2 = 2, X = 3, Z = 3, Y = 5),
  y = c(U1 = 2, U2 = 4, X = 1, Z = 2, Y = 2)
)
d_mbias <- dagify(
  Z ~ U1 + U2,
  X ~ U1,
  Y ~ X + U2,
  exposure = "X",
  outcome = "Y",
  labels = c(X = "X", Y = "Y", Z = "Z"),
  coords = coords
)

d_mbias %>%
  tidy_dagitty() %>%
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point() +
  geom_dag_edges() +
  geom_dag_text() +
  theme_dag() +
  coord_cartesian(clip = "off") +
  ggtitle("(4) M-bias") +
  expander() -> p_m_bias

d_coll %>%
  tidy_dagitty() %>%
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point() +
  geom_dag_edges() +
  geom_dag_text() +
  theme_dag() +
  coord_cartesian(clip = "off") +
  ggtitle("(1) Collider") +
  expander()  -> p_coll

d_med %>%
  tidy_dagitty() %>%
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point() +
  geom_dag_edges() +
  geom_dag_text() +
  theme_dag() +
  coord_cartesian(clip = "off") + 
  ggtitle("(3) Mediator") +
  expander()  -> p_med

d_conf %>%
  tidy_dagitty() %>%
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point() +
  geom_dag_edges() +
  geom_dag_text() +
  theme_dag() +
  coord_cartesian(clip = "off") + 
  ggtitle("(2) Confounder") + 
  expander() -> p_conf

(p_coll + plot_spacer() + p_conf) /  (p_med + plot_spacer() + p_m_bias)  
```

```{r}
#| fig-cap: "100 points generated using the data generating mechanisms specified (1) Collider (2) Confounder (3) Mediator (4) M-Bias. The blue line displays a linear regression fit estimating the relationship between X and Y; in each case, the slope is 1. "
#| label: fig-2
library(tidyverse)
# devtools::install_github("LucyMcGowan/quartet")
library(quartet)

## Figure 2

ggplot(causal_quartet, aes(x = x, y = y)) +
  geom_point(alpha = 0.25) + 
  geom_smooth(
    method = "lm", 
    formula = "y ~ x", 
    linesize = 1.1, 
    color = "steelblue"
  ) +
  facet_wrap(~dataset)
```

+---------------------------+---------------------------+-----------------------+
| Data generating mechanism | Correct causal model      | Correct causal effect |
+===========================+===========================+=======================+
| \(1\) Collider            | Y \~ X                    | 1                     |
+---------------------------+---------------------------+-----------------------+
| \(2\) Confounder          | Y \~ X + Z                | 0.5                   |
+---------------------------+---------------------------+-----------------------+
| \(3\) Mediator            | Direct effect: Y \~ X + Z | Direct effect: 0      |
|                           |                           |                       |
|                           | Total Effect: Y \~ X      | Total effect: 1       |
+---------------------------+---------------------------+-----------------------+
| \(4\) M-Bias              | Y \~ X                    | 1                     |
+---------------------------+---------------------------+-----------------------+

: Correct causal models and causal effects for each data-generating mechanism. {#tbl-1}

```{r}
#| label: tbl-2
#| tbl-cap: "Coefficients for the exposure under each data generating mechanism depending on the model fit as well as the correlation between $X$ and $Z$."

## Table 2

causal_quartet %>%
  nest_by(dataset) %>%
  mutate(`Y ~ X` = round(coef(lm(y ~ x, data = data))[2], 2),
         `Y ~ X + Z` = round(coef(lm(y ~ x + z, data = data))[2], 2),
         `Correlation of X and Z` = round(cor(data$x, data$z), 2)) %>%
  select(-data, `Data generating mechanism` = dataset) %>%
  knitr::kable()
```

## Discussion

Here we have demonstrated that when presented with an exposure, outcome, and some measured factors, statistics alone, whether summary statistics or data visualizations are insufficient to determine the appropriate causal estimate. Analysts need additional information about the data generating mechanism to draw the correct conclusions. While knowledge of the data generating process is necessary to estimate the correct causal effect in each of the cases presented, an analyst can take steps to make mistakes such as those shown here less likely. The first is discussing understood mechanisms with content matter experts before estimating causal effects. Drawing the proposed relationships via causal diagrams such as the directed acyclic graphs shown in @fig-1 before calculating any statistical quantities can help the analyst ensure they are only adjusting for factors that meet the "backdoor criterion," that is, adjusting for only factors that close all backdoor paths between the exposure and outcome of interest [@pearl2000causality]. Absent subject matter expertise, the analyst can at least consider the time ordering of the available factors. Fundamental principles of causal inference dictate that the exposure of interest must precede the outcome of interest to establish a causal relationship plausibly. In addition, to account for potential confounding, any covariates adjusted for in the analysis must precede the exposure in time. Including this additional timing information would omit the potential for two of the three misspecified models above (@eq-col the "collider" and @eq-med the "mediator") as the former would demonstrate that the factor $Z$ falls after both the exposure and outcome and the latter would show that the factor $Z$ falls between the exposure and the outcome in time.

Adjusting for only pre-exposure factors is widely recommended. The only exception is when a known confounder is only measured after the exposure in a particular data analysis, in which case some experts recommend adjusting for it. Still, even then, caution is advised [@groenwold2021adjust]. Many causal inference methodologists would recommend conditioning on *all* measured pre-exposure factors [@rosenbaumconstructing; @rubin2009should; @rubin1996matching; @rubin2008objective]. Including timing information alone (and thus adjusting for all pre-exposure factors) does not preclude one from mistakenly fitting the adjusted model under the fourth data generating mechanism (M-bias), as $Z$ can fall temporally before $X$ and $Y$ and still induce bias. It has been argued, however, that this strict M-bias (e.g., where $U_1$ and $U_2$ in @eq-mbias have no relationship with each other and $Z$ has no relationship with $X$ or $Y$ other than via $U_1$ and $U_2$) is very rare in most practical settings [@liu2012implications; @rubin2009should; @gelman2011causality]. Indeed, even theoretical results have demonstrated that bias induced by this data generating mechanism is sensitive to any deviations from this form [@ding2015adjust]. 

We have presented four example data sets demonstrating the importance of understanding the data-generating mechanism when attempting to answer causal questions. These data indicate that more than statistical summaries and visualizations are needed to provide insight into the underlying relationship between the variables. An understanding or assumption of the data-generating mechanism is required to capture causal relationships correctly. These examples underscore the limitations of relying solely on statistical tools in data analyses and highlight the crucial role of domain-specific knowledge. Moreover, they emphasize the importance of considering the timing of factors when deciding what to adjust for.

## References

::: {#refs}
:::

## Appendix {.appendix}

R code to generate the tables and figures:

```{r}
#| eval: false
#| echo: true
#| ref.label: ["fig-2", "tbl-2"]
```

